{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c59eca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "max_len = 40\n",
    "num_classes = 6\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "983648cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\vmakh\\OneDrive\\Desktop\\Python-20220419T075236Z-001\\Python\\Neuron Networks\\NLP\\lection6_materials\\lection6_materials\\task.xls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bc80644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20659, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c32840db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                               text        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'Content': 'text'})\n",
    "df = df.rename(columns={'Rating': 'rating'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "408f47b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    14586\n",
       "1     2276\n",
       "4     2138\n",
       "3      911\n",
       "2      748\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dc38e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fd3758d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "181c7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['rating'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e1a7e6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16527,), (4132,))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "aa10f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(X_train)\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "02ce2bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it just works целое удобноной приложениеиз минус хотеть большой доступ персональный данные телефонеп'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4a16a252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vmakh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5fca21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1fc21d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9465ebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['приложение',\n",
       " 'удобно',\n",
       " 'работать',\n",
       " 'удобный',\n",
       " 'отлично',\n",
       " 'нравиться',\n",
       " 'хороший',\n",
       " 'отличный',\n",
       " 'телефон',\n",
       " 'супер']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bd164dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "105330aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4d97c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
    "X_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fb129562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16527, 40), (4132, 40))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8466c3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, 56, 44, 45, 20,  1])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fa9cb4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16527,), (4132,))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c5f2b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5614600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16527, 6), (4132, 6))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "702860ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "#from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "32d786bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ef7e57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a46f3ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 14s 404ms/step - loss: 1.2556 - accuracy: 0.6946 - val_loss: 1.0051 - val_accuracy: 0.7072\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 13s 425ms/step - loss: 0.8986 - accuracy: 0.7049 - val_loss: 0.8202 - val_accuracy: 0.7072\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 12s 411ms/step - loss: 0.7904 - accuracy: 0.7049 - val_loss: 0.7771 - val_accuracy: 0.7072\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.7567 - accuracy: 0.7048 - val_loss: 0.7634 - val_accuracy: 0.7072\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 23s 751ms/step - loss: 0.7430 - accuracy: 0.7062 - val_loss: 0.7530 - val_accuracy: 0.7072\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 26s 868ms/step - loss: 0.7322 - accuracy: 0.7075 - val_loss: 0.7496 - val_accuracy: 0.7157\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.7244 - accuracy: 0.7121 - val_loss: 0.7431 - val_accuracy: 0.7151\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 29s 956ms/step - loss: 0.7158 - accuracy: 0.7125 - val_loss: 0.7380 - val_accuracy: 0.7157\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 25s 822ms/step - loss: 0.7091 - accuracy: 0.7140 - val_loss: 0.7363 - val_accuracy: 0.7193\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 26s 870ms/step - loss: 0.7006 - accuracy: 0.7172 - val_loss: 0.7293 - val_accuracy: 0.7199\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 29s 959ms/step - loss: 0.6913 - accuracy: 0.7203 - val_loss: 0.7242 - val_accuracy: 0.7302\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 27s 913ms/step - loss: 0.6801 - accuracy: 0.7457 - val_loss: 0.7186 - val_accuracy: 0.7508\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6703 - accuracy: 0.7702 - val_loss: 0.7126 - val_accuracy: 0.7604\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 27s 864ms/step - loss: 0.6556 - accuracy: 0.7756 - val_loss: 0.7032 - val_accuracy: 0.7623\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.6413 - accuracy: 0.7785 - val_loss: 0.7036 - val_accuracy: 0.7574\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=r'C:\\Users\\vmakh\\OneDrive\\Desktop\\Python-20220419T075236Z-001\\Python\\Neuron Networks\\NLP\\lection7\\lection7\\logs', write_graph=True, write_images=True)\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "75782770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16527, 40), (16527, 6))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4bcc6b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 230ms/step - loss: 0.7028 - accuracy: 0.7611\n",
      "\n",
      "\n",
      "Test score: 0.702793538570404\n",
      "Test accuracy: 0.7611325979232788\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ead8ef0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4132, 40), (4132, 6))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "976c4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5d9b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09e8ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = vect.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c22a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "674c14a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmakh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(train_ft, df['rating'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dc149096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "414/414 [==============================] - 103s 231ms/step - loss: 1.0049 - accuracy: 0.7064 - val_loss: 1.0122 - val_accuracy: 0.6936\n",
      "Epoch 2/10\n",
      "414/414 [==============================] - 92s 221ms/step - loss: 0.9790 - accuracy: 0.7080 - val_loss: 1.0173 - val_accuracy: 0.6936\n",
      "Epoch 3/10\n",
      "414/414 [==============================] - 90s 216ms/step - loss: 0.9789 - accuracy: 0.7080 - val_loss: 1.0137 - val_accuracy: 0.6936\n",
      "Epoch 4/10\n",
      "414/414 [==============================] - 80s 193ms/step - loss: 0.9779 - accuracy: 0.7080 - val_loss: 1.0170 - val_accuracy: 0.6936\n",
      "Epoch 5/10\n",
      "414/414 [==============================] - 86s 208ms/step - loss: 0.9784 - accuracy: 0.7080 - val_loss: 1.0118 - val_accuracy: 0.6936\n",
      "Epoch 6/10\n",
      "414/414 [==============================] - 75s 182ms/step - loss: 0.9780 - accuracy: 0.7080 - val_loss: 1.0189 - val_accuracy: 0.6936\n",
      "Epoch 7/10\n",
      "414/414 [==============================] - 92s 221ms/step - loss: 0.9766 - accuracy: 0.7080 - val_loss: 1.0157 - val_accuracy: 0.6936\n",
      "Epoch 8/10\n",
      "414/414 [==============================] - 82s 198ms/step - loss: 0.9774 - accuracy: 0.7080 - val_loss: 1.0129 - val_accuracy: 0.6936\n",
      "Epoch 9/10\n",
      "414/414 [==============================] - 90s 217ms/step - loss: 0.9775 - accuracy: 0.7080 - val_loss: 1.0137 - val_accuracy: 0.6936\n",
      "Epoch 10/10\n",
      "414/414 [==============================] - 82s 198ms/step - loss: 0.9762 - accuracy: 0.7080 - val_loss: 1.0132 - val_accuracy: 0.6936\n",
      "130/130 [==============================] - 13s 103ms/step - loss: 0.9789 - accuracy: 0.7096\n",
      "Test Loss: 0.9789\n",
      "Test Accuracy: 0.7096\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import gensim.downloader as api\n",
    "\n",
    "maxlen=40\n",
    "\n",
    "# Step 2: Load the pre-trained Word2Vec model\n",
    "model = api.load(\"word2vec-ruscorpora-300\")\n",
    "\n",
    "# Step 3: Initialize the embedding matrix with pre-trained vectors\n",
    "embedding_dim = 300  # Dimension of the word embeddings\n",
    "vocab_size = len(vocabulary) + 1  # Vocabulary size\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in vocabulary.items():\n",
    "    if word in model.key_to_index:\n",
    "        embedding_matrix[idx] = model[word]\n",
    "\n",
    "# Step 4: Define the model architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, embedding_dim)))  # Update input shape to (maxlen, embedding_dim)\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    np.array(X_train), np.array(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = model.evaluate(np.array(X_test), np.array(y_test))\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21dd3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
